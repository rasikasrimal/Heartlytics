{% extends "base.html" %}
{% block title %}Research | Heart Disease Risk{% endblock %}
{% block content %}
<article class="container-xxl">
  <header class="mb-4">
    <h1 class="mb-1">Prediction of Heart Disease Using Machine Learning Algorithms</h1>
    <p class="text-muted mb-0">HMRS Samaranayaka</p>
    <p class="text-muted">Department of Computer Science &amp; Software Engineering, NSBM Green University, Sri Lanka</p>
  </header>

  <section class="mb-4">
    <h2 class="h5">Abstract</h2>
    <p>
      We present a machine‑learning approach for predicting heart disease using the UCI dataset.
      The pipeline includes robust preprocessing (imputation, outlier handling, scaling),
      exploratory data analysis, and model development with ensemble methods (Random Forest, XGBoost).
      Models are tuned via cross‑validation and evaluated with accuracy, precision, recall, F1‑score
      and ROC‑AUC. The best model is deployed in a Flask application for interactive what‑if
      simulations and educational use.
    </p>
  </section>

  <section class="mb-4">
    <h2 class="h5">Keywords</h2>
    <p>Heart Disease, Machine Learning, Random Forest, XGBoost, Exploratory Data Analysis, Flask</p>
  </section>

  <section class="mb-4">
    <h2 class="h5">Introduction</h2>
    <p>
      Cardiovascular diseases remain a leading cause of death globally. Early detection can reduce
      morbidity and mortality, and data‑driven methods can complement clinical workflows by
      identifying patterns across demographic and clinical variables. Recent studies highlight the
      effectiveness of tree‑based ensembles for such tabular problems.
    </p>
  </section>

  <section class="mb-4">
    <h2 class="h5">Dataset &amp; EDA</h2>
    <p>
      We use the consolidated UCI Heart Disease dataset (~920 rows). Key variables include age,
      sex, chest pain type, resting blood pressure, cholesterol, maximum heart rate, ST depression,
      number of vessels and thalassemia. EDA examines distributions and relationships (e.g., chest
      pain type vs outcome, age distributions by site) and informs preprocessing choices.
    </p>
  </section>

  <section class="mb-4">
    <h2 class="h5">Methodology</h2>
    <ul>
      <li><strong>Preprocessing:</strong> imputation for missing values; IQR and Isolation Forest for outlier handling; standardization for numeric features.</li>
      <li><strong>Models:</strong> Random Forest (balanced classes) and XGBoost; hyperparameters tuned with stratified CV.</li>
      <li><strong>Evaluation:</strong> accuracy, precision, recall, F1, ROC‑AUC; confusion matrices for error analysis.</li>
      <li><strong>Deployment:</strong> best model exposed via a Flask app supporting simulations and PDF export.</li>
    </ul>
  </section>

  <section class="mb-4">
    <h2 class="h5">Results</h2>
    <p>
      Both ensembles perform competitively on a held‑out test set; XGBoost slightly outperforms
      Random Forest in overall accuracy with comparable recall for the positive class. Model choice
      may be guided by desired interpretability vs. marginal performance gains.
    </p>
  </section>

  <section class="mb-5">
    <h2 class="h5">Conclusion</h2>
    <p>
      The project validates ensemble ML methods for heart disease risk prediction and demonstrates
      a practical, interactive interface. Future work includes calibration, prospective validation,
      and fairness audits across demographic groups.
    </p>
  </section>

  <footer class="text-muted small">This page uses standard HTML/CSS/JS (no LaTeX parsing).</footer>
</article>
{% endblock %}

